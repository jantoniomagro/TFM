\chapter{Overview}

\pagenumbering{arabic}

The volume of data produced at some science centers presents a considerable processing challenge. At CERN, for instance, several hundred million times per second, particles collide inside LHC. Each collision generates particles that often decay in complex ways into more particles. The pass of particles are recorded through a detector that sends the data for digital reconstruction. Physicists have then to browse through petabytes of data annually yielded to determine if the collisions have thrown up any interesting information.

CERN, like many other science centers, does not have the computing or financial resources to manage all of the data on its site, so it moved into the grid to share the load with computing centers around the world. The Worldwide LHC Computing Grid is a distributed system which gives over 8000 physicists near real-time access to LHC data.

So we could think that current deployed technologies are maybe obsolete and a new rethink should be made. If CERN (but not just CERN as we will discuss later) has changed its storage policy (leaving behind the classic client-server model), why not change the way the data are accessed? 

Almost a decade after E. Codd published his famous relational model paper, the relational database management systems (RDBMS) have been the \textit{de facto} tools. Today, non-relational, cloud, or the so-called NoSQL databases are growing rapidly as an alternative model for database management. Often more features apply such as schema-less, easy replication feature, simple API, eventually consistent / BASE (not ACID), a huge amount of data (big data) and more. 

In this work, we give a short overview of big data problem and present an alternative, using one of the NoSQL databases (today, the volumes of data that can be handled by NoSQL systems exceed what can be handled by the biggest RDBMS) freely available, to offer a different way of challenging some of these problems, always operating inside VO frame.